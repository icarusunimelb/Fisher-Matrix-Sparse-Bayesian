{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simplified demo compared to experiments in the paper. To reproduce the results, increase training epoches and sample size, and add weight decay. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Ana\\envs\\torch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "D:\\Ana\\envs\\torch\\lib\\site-packages\\deeplake\\util\\check_latest_version.py:32: UserWarning: A newer version of deeplake (3.8.13) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Standard imports\n",
    "import os\n",
    "import copy\n",
    "import collections\n",
    "import numpy as np\n",
    "from numpy.linalg import inv, cholesky\n",
    "from typing import Union, List, Any, Dict\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.nn import Module, Sequential\n",
    "import torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import deeplake\n",
    "\n",
    "# From the repository\n",
    "from plot import surface_plot\n",
    "from curvatures import Diagonal, KFAC, EFB, INF,Curvature, BlockDiagonal\n",
    "from utils import calibration_curve,get_eigenvectors, kron, expected_calibration_error, predictive_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to 'cuda' if you have a working GPU.\n",
    "device = 'cuda'\n",
    "\n",
    "def train(model, data, criterion, optimizer, epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for images, labels in tqdm(data):\n",
    "            logits = model(images.to(device))\n",
    "\n",
    "            loss = criterion(logits, labels.to(device))\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "def eval(model_, data):\n",
    "    model_.eval()\n",
    "    logits = torch.Tensor().to(device)\n",
    "    targets = torch.LongTensor()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(data):\n",
    "            logits = torch.cat([logits, model_(images.to(device))])\n",
    "            targets = torch.cat([targets, labels])\n",
    "    return torch.nn.functional.softmax(logits, dim=1), targets\n",
    "\n",
    "def eval_ood(model_, data):\n",
    "    model_.eval()\n",
    "    logits = torch.Tensor().to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for item in tqdm(data):\n",
    "            logits = torch.cat([logits, model_(item['images'].float() .unsqueeze(1).to(device))])\n",
    "    return torch.nn.functional.softmax(logits, dim=1)\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "    print(f\"Accuracy: {100 * np.mean(np.argmax(predictions.cpu().numpy(), axis=1) == labels.numpy()):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a PyTorch model (or load a pretrained one).\n",
    "class Flatten(torch.nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "# This tutorial uses a LeNet-5 variant.\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(1, 6, 5, padding=2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2, 2),\n",
    "    torch.nn.Conv2d(6, 16, 5),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(2, 2),\n",
    "    Flatten(),\n",
    "    torch.nn.Linear(16 * 5 * 5, 120),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(120, 84),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(84, 10)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some data for training\n",
    "torch_data = \"~/.torch/datasets\"  # Standard PyTorch dataset location\n",
    "train_set = torchvision.datasets.MNIST(root=torch_data,\n",
    "                                       train=True,\n",
    "                                       transform=torchvision.transforms.ToTensor(),\n",
    "                                       download=True)\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=32)\n",
    "\n",
    "# And some for evaluating/testing\n",
    "test_set = torchvision.datasets.MNIST(root=torch_data,\n",
    "                                      train=False,\n",
    "                                      transform=torchvision.transforms.ToTensor(),\n",
    "                                      download=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening dataset in read-only mode as you don't have write permissions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/not-mnist-small\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hub://activeloop/not-mnist-small loaded successfully.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "-"
     ]
    }
   ],
   "source": [
    "# Out-of-distribution dataset\n",
    "ds = deeplake.load('hub://activeloop/not-mnist-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Ana\\envs\\torch\\lib\\site-packages\\deeplake\\integrations\\pytorch\\common.py:137: UserWarning: Decode method for tensors ['images'] is defaulting to numpy. Please consider specifying a decode_method in .pytorch() that maximizes the data preprocessing speed based on your transformation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "ood_loader = ds.pytorch(num_workers=0, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [00:59<00:00, 31.76it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [00:50<00:00, 36.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# Train the model (or load a pretrained one)\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "train(model, train_loader, criterion, optimizer, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:04<00:00,  9.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model (optional)\n",
    "sgd_predictions, sgd_labels = eval(model, test_loader)\n",
    "accuracy(sgd_predictions, sgd_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011540600928664237\n"
     ]
    }
   ],
   "source": [
    "sgd_ece = expected_calibration_error(sgd_predictions.cpu().detach().numpy(), sgd_labels.cpu().detach().numpy(), 10)\n",
    "print(sgd_ece[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4681/4681 [00:45<00:00, 103.64it/s]\n"
     ]
    }
   ],
   "source": [
    "sgd_ood_predictions = eval_ood(model, ood_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0020425383\n"
     ]
    }
   ],
   "source": [
    "sgd_entropy = predictive_entropy(sgd_ood_predictions.cpu().detach().numpy(), True)\n",
    "print(sgd_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant\n",
    "samples = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1875 [00:00<?, ?it/s]D:\\Ana\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1053: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [00:58<00:00, 32.11it/s]\n",
      "D:\\OneDrive - Deakin University\\Fisher-Matrix-Sparse-Bayesian\\utils.py:49: UserWarning: torch.symeig is deprecated in favor of torch.linalg.eigh and will be removed in a future PyTorch release.\n",
      "The default behavior has changed from using the upper triangular portion of the matrix by default to using the lower triangular portion.\n",
      "L, _ = torch.symeig(A, upper=upper)\n",
      "should be replaced with\n",
      "L = torch.linalg.eigvalsh(A, UPLO='U' if upper else 'L')\n",
      "and\n",
      "L, V = torch.symeig(A, eigenvectors=True)\n",
      "should be replaced with\n",
      "L, V = torch.linalg.eigh(A, UPLO='U' if upper else 'L') (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\BatchLinearAlgebra.cpp:3041.)\n",
      "  _, xxt_eigvecs = torch.symeig(sym_xxt, eigenvectors=True)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1875/1875 [00:57<00:00, 32.54it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  5.38it/s]\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "diag = Diagonal(model, last_layer_mode = True)\n",
    "kfac = KFAC(model, last_layer_mode = True)\n",
    "\n",
    "for images, labels in tqdm(train_loader):\n",
    "    logits = model(images.to(device))\n",
    "    loss = criterion(logits, labels.to(device)) \n",
    "    model.zero_grad()\n",
    "    loss.backward(retain_graph=True)\n",
    "\n",
    "    diag.update(batch_size=images.size(0))\n",
    "    kfac.update(batch_size=images.size(0))\n",
    "        \n",
    "ckfac = EFB(model, kfac.state, last_layer_mode = True)\n",
    "\n",
    "for images, labels in tqdm(train_loader):\n",
    "    logits = model(images.to(device))\n",
    "    loss = criterion(logits, labels.to(device))\n",
    "    model.zero_grad()\n",
    "    loss.backward(retain_graph=True)\n",
    "\n",
    "    ckfac.update(batch_size=images.size(0))\n",
    "\n",
    "llla = INF(model, diag.state, kfac.state, ckfac.state, last_layer_mode = True)\n",
    "llla.update(rank=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2350\n"
     ]
    }
   ],
   "source": [
    "count_llla = 0\n",
    "for index, (layer, value) in enumerate(llla.state.items()):\n",
    "    count_llla += value[0].shape[0]*value[0].shape[1]+value[1].shape[0]*value[1].shape[1]+value[2].shape[0]+value[3].shape[0]\n",
    "print(count_llla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\OneDrive - Deakin University\\Fisher-Matrix-Sparse-Bayesian\\curvatures.py:622: UserWarning: torch.cholesky is deprecated in favor of torch.linalg.cholesky and will be removed in a future PyTorch release.\n",
      "L = torch.cholesky(A)\n",
      "should be replaced with\n",
      "L = torch.linalg.cholesky(A)\n",
      "and\n",
      "U = torch.cholesky(A, upper=True)\n",
      "should be replaced with\n",
      "U = torch.linalg.cholesky(A).mH().\n",
      "This transform will produce equivalent results for all valid (symmetric positive definite) inputs. (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\BatchLinearAlgebra.cpp:1755.)\n",
      "  A_c_inv = vtv.cholesky().inverse()\n"
     ]
    }
   ],
   "source": [
    "# prior precision and likelihood scale parameter\n",
    "add = 100.0\n",
    "multiply = 20.0\n",
    "llla.invert(add, multiply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:04<00:00,  8.29it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 4681/4681 [01:00<00:00, 77.20it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:04<00:00,  9.36it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 4681/4681 [00:47<00:00, 98.07it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:04<00:00,  9.25it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 4681/4681 [01:01<00:00, 75.69it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:04<00:00,  9.34it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 4681/4681 [00:48<00:00, 95.91it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:04<00:00,  8.55it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 4681/4681 [00:51<00:00, 90.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.40%\n"
     ]
    }
   ],
   "source": [
    "mean_predictions = 0\n",
    "mean_ood_predictions = 0\n",
    "with torch.no_grad():\n",
    "    for sample in range(samples):\n",
    "        llla.sample_and_replace()\n",
    "        predictions, labels = eval(model, test_loader)\n",
    "        ood_predictions = eval_ood(model, ood_loader)\n",
    "        mean_predictions += predictions\n",
    "        mean_ood_predictions += ood_predictions\n",
    "    mean_predictions /= samples\n",
    "    mean_ood_predictions /= samples\n",
    "accuracy(mean_predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.017216112053394336\n"
     ]
    }
   ],
   "source": [
    "llla_ece = expected_calibration_error(mean_predictions.cpu().detach().numpy(), labels.cpu().detach().numpy(), 10)\n",
    "print(llla_ece[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14972506\n"
     ]
    }
   ],
   "source": [
    "llla_entropy = predictive_entropy(mean_ood_predictions.cpu().detach().numpy(), True)\n",
    "print(llla_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
